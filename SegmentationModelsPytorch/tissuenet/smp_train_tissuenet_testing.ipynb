{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcc6c4-893e-4617-bb10-fa0b7d996024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "#import albumentations as A\n",
    "#from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import v2\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "from smp_dataset_tissuenet import SMPDatasetTissuenet\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48636caf-a569-44b2-8ad2-565bfdda48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Hyperparams\n",
    "\n",
    "#os.chdir('c:/users/fre_f/pythonprojects/cellvision/unetscratch/')\n",
    "lr = 0.0001\n",
    "weight_decay = 1e-8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "batch_size = 20\n",
    "epochs = 100\n",
    "pin_memory = True\n",
    "train_img_dir = \"insert_path\"\n",
    "train_mask_dir = \"insert_path\"\n",
    "test_img_dir = \"insert_path\"\n",
    "test_mask_dir = \"insert_path\"\n",
    "model_name = f'UNet++_{epochs}Epochs_lr{lr}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40444ed-c60d-4e14-9217-e22b1ce717d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Instantiate dataset\n",
    "\n",
    "#train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\"\"\"\n",
    "train_transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Resize((256,256)),\n",
    "])\n",
    "\"\"\"\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "                    v2.ToImage(), \n",
    "                    v2.Resize((256,256)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0f450-7da3-4c12-b5ec-e1ef2c7a2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "train_ds = SMPDatasetTissuenet(\n",
    "    image_dir=train_img_dir,\n",
    "    mask_dir=train_mask_dir,\n",
    "    transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed2b21-6022-4153-85ea-eb4119f5d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Instatiate dataloader\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=pin_memory,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8598ec9-29ed-48d1-9b69-f0a60734c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Example image\n",
    "\n",
    "image, mask = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a3b1b-d52a-4e0f-8d31-f5d583d6b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93d453-5096-46b8-9781-4e4af7c27814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6477d-c38e-4d3b-8730-b0b3215f8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualize images\n",
    "\n",
    "image_train, mask_train = next(iter(train_dl))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "axs[0].imshow(np.transpose(image_train[0, :, :, :].cpu().numpy(), (1, 2, 0)))\n",
    "axs[0].set_title('Image')\n",
    "axs[1].imshow(np.transpose(mask_train[0, :, :].cpu().numpy(), (1, 2, 0))).cmap='gray'\n",
    "axs[1].set_title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9ea94-9895-4c1a-b3a5-8541e544d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "mask_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4962f6a-1726-40a9-a368-bc4eeab4791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "print(torch.Tensor(image_train).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f376862-0cce-4175-a37d-234e15e2e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Train model\n",
    "\n",
    "epoch_losses = []\n",
    "metric = BinaryJaccardIndex()\n",
    "metric.to(device)\n",
    "\n",
    "def train():\n",
    "    model = smp.UnetPlusPlus(\n",
    "                encoder_name='resnet34',\n",
    "                encoder_weights='imagenet',\n",
    "                classes=1,\n",
    "                activation=None).to(device)\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    #criterion = nn.BCEWithLogitsLoss() #BCEwithlogits has sigmoid incl. \n",
    "    criterion = smp.losses.DiceLoss('binary')\n",
    "\n",
    "    input, target = next(iter(train_dl))\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        #input = input.type(torch.float).to(device)\n",
    "        #target = target.type(torch.float).to(device) #.unsqueeze(1) \n",
    "        input = input.type(torch.float).to(device)\n",
    "        target = target.to(device)\n",
    "        # to skip last item if batch size == 1\n",
    "        if input.shape[0] < 2:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(input)\n",
    "        #preds = preds.type(torch.float)\n",
    "        loss = criterion(preds, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iou = metric(preds, target)\n",
    "        #tqdm.set_description(f'Epoch [{epoch}/{epochs}]')\n",
    "        #tqdm.set_postfix(loss=loss.item(), iou=iou, lr=lr)\n",
    "        epoch_losses.append(loss.item())\n",
    "    if epoch % 25 == 1:\n",
    "        print(f'Loss on Epoch {epoch}: {sum(epoch_losses)/len(epoch_losses)}')\n",
    "        print(f'IOU on Epoch {epoch}: {iou}')\n",
    "    print('Training complete. Model saved!')\n",
    "\n",
    "if __name__== '__main__':\n",
    "    train()\n",
    "\n",
    "iou_train = metric.compute()\n",
    "print(f'Final training IOU: {iou_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e3672-6125-4183-9a0a-00518324b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "sns.lineplot(x=range(len(epoch_losses)), y=epoch_losses).set(title='Train Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
