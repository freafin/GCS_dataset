{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code has been heavily inspired by: \n",
    "# Bhattiprolu, S. (2023). python_for_microscopists. GitHub.\n",
    "# https://github.com/bnsreenu/python_for_microscopists/blob/master/332%20-%20All%20about%20image%20annotations%E2%80%8B/binary_to_coco_V3.0.py\n",
    "# Only minor changes has been made. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis code automates the conversion of binary masks representing different \\nobject categories into the COCO (Common Objects in Context) JSON format. \\n\\nThe code is based on the following folder structure for training and validation\\nimages and masks. You need to change the code based on your folder structure \\nor organize your data to the format below.\\n\\nEM-platelet-multi/   #Primary data folder for the project\\n├── input/           #All input data is stored here. \\n│   ├── train_images/\\n│   │   ├── image01.png\\n│   │   ├── image02.png\\n│   │   └── ...\\n│   ├── train_masks/        #All binary masks organized in respective sub-directories.\\n│   │   ├── Alpha/\\n│   │   │   ├── image01.png\\n│   │   │   ├── image02.png\\n│   │   │   └── ...\\n│   │   ├── Cells/\\n│   │   │   ├── image01.png\\n│   │   │   ├── image02.png\\n│   │   │   └── ...\\n│   │   ├── Mito/\\n│   │   │   ├── image01.png\\n│   │   │   ├── image02.png\\n│   │   │   └── ...\\n│   │   └── Vessels/\\n│   │       ├── image01.png\\n│   │       ├── image02.png\\n│   │       └── ...\\n│   ├── val_images/\\n│   │   ├── image05.png\\n│   │   ├── image06.png\\n│   │   └── ...\\n│   └── val_masks/\\n│       ├── Alpha/\\n│       │   ├── image05.png\\n│       │   ├── image06.png\\n│       │   └── ...\\n│       ├── Cells/\\n│       │   ├── image05.png\\n│       │   ├── image06.png\\n│       │   └── ...\\n│       ├── Mito/\\n│       │   ├── image05.png\\n│       │   ├── image06.png\\n│       │   └── ...\\n│       └── Vessels/\\n│           ├── image05.png\\n│           ├── image06.png\\n│           └── ...\\n└── ...\\n\\n\\nFor each binary mask, the code extracts contours using OpenCV. \\nThese contours represent the boundaries of objects within the images.This is a key\\nstep in converting binary masks to polygon-like annotations. \\n\\nConvert the contours into annotations, including \\nbounding boxes, area, and segmentation information. Each annotation is \\nassociated with an image ID, category ID, and other properties required by the COCO format.\\n\\nThe code also creates an images section containing \\nmetadata about the images, such as their filenames, widths, and heights.\\nIn my example, I have used exactly the same file names for all images and masks\\nso that a given mask can be easily mapped to the image. \\n\\nAll the annotations, images, and categories are \\nassembled into a dictionary that follows the COCO JSON format. \\nThis includes sections for \"info,\" \"licenses,\" \"images,\" \"categories,\" and \"annotations.\"\\n\\nFinally, the assembled COCO JSON data is saved to a file, \\nmaking it ready to be used with tools and frameworks that support the COCO data format.\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://youtu.be/NYeJvxe5nYw\n",
    "\"\"\"\n",
    "This code automates the conversion of binary masks representing different \n",
    "object categories into the COCO (Common Objects in Context) JSON format. \n",
    "\n",
    "The code is based on the following folder structure for training and validation\n",
    "images and masks. You need to change the code based on your folder structure \n",
    "or organize your data to the format below.\n",
    "\n",
    "EM-platelet-multi/   #Primary data folder for the project\n",
    "├── input/           #All input data is stored here. \n",
    "│   ├── train_images/\n",
    "│   │   ├── image01.png\n",
    "│   │   ├── image02.png\n",
    "│   │   └── ...\n",
    "│   ├── train_masks/        #All binary masks organized in respective sub-directories.\n",
    "│   │   ├── Alpha/\n",
    "│   │   │   ├── image01.png\n",
    "│   │   │   ├── image02.png\n",
    "│   │   │   └── ...\n",
    "│   │   ├── Cells/\n",
    "│   │   │   ├── image01.png\n",
    "│   │   │   ├── image02.png\n",
    "│   │   │   └── ...\n",
    "│   │   ├── Mito/\n",
    "│   │   │   ├── image01.png\n",
    "│   │   │   ├── image02.png\n",
    "│   │   │   └── ...\n",
    "│   │   └── Vessels/\n",
    "│   │       ├── image01.png\n",
    "│   │       ├── image02.png\n",
    "│   │       └── ...\n",
    "│   ├── val_images/\n",
    "│   │   ├── image05.png\n",
    "│   │   ├── image06.png\n",
    "│   │   └── ...\n",
    "│   └── val_masks/\n",
    "│       ├── Alpha/\n",
    "│       │   ├── image05.png\n",
    "│       │   ├── image06.png\n",
    "│       │   └── ...\n",
    "│       ├── Cells/\n",
    "│       │   ├── image05.png\n",
    "│       │   ├── image06.png\n",
    "│       │   └── ...\n",
    "│       ├── Mito/\n",
    "│       │   ├── image05.png\n",
    "│       │   ├── image06.png\n",
    "│       │   └── ...\n",
    "│       └── Vessels/\n",
    "│           ├── image05.png\n",
    "│           ├── image06.png\n",
    "│           └── ...\n",
    "└── ...\n",
    "\n",
    "\n",
    "For each binary mask, the code extracts contours using OpenCV. \n",
    "These contours represent the boundaries of objects within the images.This is a key\n",
    "step in converting binary masks to polygon-like annotations. \n",
    "\n",
    "Convert the contours into annotations, including \n",
    "bounding boxes, area, and segmentation information. Each annotation is \n",
    "associated with an image ID, category ID, and other properties required by the COCO format.\n",
    "\n",
    "The code also creates an images section containing \n",
    "metadata about the images, such as their filenames, widths, and heights.\n",
    "In my example, I have used exactly the same file names for all images and masks\n",
    "so that a given mask can be easily mapped to the image. \n",
    "\n",
    "All the annotations, images, and categories are \n",
    "assembled into a dictionary that follows the COCO JSON format. \n",
    "This includes sections for \"info,\" \"licenses,\" \"images,\" \"categories,\" and \"annotations.\"\n",
    "\n",
    "Finally, the assembled COCO JSON data is saved to a file, \n",
    "making it ready to be used with tools and frameworks that support the COCO data format.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"insert_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label IDs of the dataset representing different categories\n",
    "category_ids = {\n",
    "    \"Cell\": 1,\n",
    "}\n",
    "\n",
    "MASK_EXT = 'png'\n",
    "ORIGINAL_EXT = 'png'\n",
    "image_id = 0\n",
    "annotation_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_annotations_info(maskpath):\n",
    "    \"\"\"\n",
    "    Process the binary masks and generate images and annotations information.\n",
    "\n",
    "    :param maskpath: Path to the directory containing binary masks\n",
    "    :return: Tuple containing images info, annotations info, and annotation count\n",
    "    \"\"\"\n",
    "    global image_id, annotation_id\n",
    "    annotations = []\n",
    "    images = []\n",
    "\n",
    "    # Iterate through categories and corresponding masks\n",
    "    for category in category_ids.keys():\n",
    "        for mask_image in glob.glob(os.path.join(maskpath, category, f'*.{MASK_EXT}')):\n",
    "            original_file_name = f'{os.path.basename(mask_image).split(\".\")[0]}.{ORIGINAL_EXT}'\n",
    "            # open as numpy array and increase pixel values to avoid missing masks \n",
    "            #mask_image_array = imread(mask_image)\n",
    "            mask = Image.open(mask_image)\n",
    "            mask_image_array = np.array(mask)\n",
    "            mask_gray = cv2.cvtColor(mask_image_array, cv2.COLOR_BGRA2GRAY)\n",
    "            mask_image_binary_array = np.where(mask_gray > np.min(mask_gray), 255, 0)\n",
    "            mask_image_binary = mask_image_binary_array.astype(np.uint8)\n",
    "            # Get image dimensions\n",
    "            height, width = mask_image_binary.shape \n",
    "\n",
    "            # Create or find existing image annotation\n",
    "            if original_file_name not in map(lambda img: img['file_name'], images):\n",
    "                image = {\n",
    "                    \"id\": image_id + 1,\n",
    "                    \"width\": width,\n",
    "                    \"height\": height,\n",
    "                    \"file_name\": original_file_name,\n",
    "                }\n",
    "                images.append(image)\n",
    "                image_id += 1\n",
    "            else:\n",
    "                image = [element for element in images if element['file_name'] == original_file_name][0]\n",
    "\n",
    "            # Find contours in the mask image\n",
    "            _, thresh = cv2.threshold(mask_image_binary, 0, 255, cv2.THRESH_BINARY) \n",
    "            contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "            # Create annotation for each contour\n",
    "            for contour in contours:\n",
    "                bbox = cv2.boundingRect(contour)\n",
    "                area = cv2.contourArea(contour)\n",
    "                segmentation = contour.flatten().tolist()\n",
    "\n",
    "                annotation = {\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image['id'],\n",
    "                    \"category_id\": category_ids[category],\n",
    "                    \"bbox\": bbox,\n",
    "                    \"area\": area,\n",
    "                    \"segmentation\": [segmentation],\n",
    "                }\n",
    "\n",
    "                # Add annotation if area is greater than zero\n",
    "                if area > 0:\n",
    "                    annotations.append(annotation)\n",
    "                    annotation_id += 1\n",
    "\n",
    "    return images, annotations, annotation_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 452313 annotations for images in folder: ./train_masks/\n",
      "Created 49522 annotations for images in folder: ./val_masks/\n"
     ]
    }
   ],
   "source": [
    "def process_masks(mask_path, dest_json):\n",
    "    global image_id, annotation_id\n",
    "    image_id = 0\n",
    "    annotation_id = 0\n",
    "\n",
    "    # Initialize the COCO JSON format with categories\n",
    "    coco_format = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"images\": [],\n",
    "        \"categories\": [{\"id\": value, \"name\": key, \"supercategory\": key} for key, value in category_ids.items()],\n",
    "        \"annotations\": [],\n",
    "    }\n",
    "\n",
    "    # Create images and annotations sections\n",
    "    coco_format[\"images\"], coco_format[\"annotations\"], annotation_cnt = images_annotations_info(mask_path)\n",
    "\n",
    "    # Save the COCO JSON to a file\n",
    "    with open(dest_json, \"w\") as outfile:\n",
    "        json.dump(coco_format, outfile, sort_keys=True, indent=4)\n",
    "\n",
    "    print(\"Created %d annotations for images in folder: %s\" % (annotation_cnt, mask_path))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_mask_path = \"./train_masks/\"\n",
    "    train_json_path = \"./train_images/train.json\"\n",
    "    process_masks(train_mask_path, train_json_path)\n",
    "\n",
    "    val_mask_path = \"./val_masks/\"\n",
    "    val_json_path = \"./val_images/test.json\"\n",
    "    process_masks(val_mask_path, val_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
